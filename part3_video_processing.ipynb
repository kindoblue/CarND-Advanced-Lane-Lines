{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def binary(img, s_thresh=(115, 255), l_thresh=(84, 255), sx_thresh=(25, 100)):\n",
    "    \"\"\"This function get an input image and return a binary images with\n",
    "       lane lines detected. \n",
    "       The saturation, lightness, gradient thresholds can be customized \n",
    "       for experimentation. The default values are the one I found the best \n",
    "       choice for the images at hand\"\"\"\n",
    "\n",
    "    # copy the input image to avoid changing it\n",
    "    img = np.copy(img)\n",
    "\n",
    "    # convert to HLS color space and separate the lightness\n",
    "    # and saturation channels\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:, :, 1]\n",
    "    s_channel = hsv[:, :, 2]\n",
    "\n",
    "    # apply sobel filter in the x direction\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)\n",
    "\n",
    "    # get the absolute value because also negative gradients represents\n",
    "    # vertical changes\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "\n",
    "    # redistribute values on the entire 0..255 range\n",
    "    scaled_sobel = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n",
    "\n",
    "    # threshold the x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[\n",
    "        (scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 255\n",
    "\n",
    "    # threshold the saturation channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 255\n",
    "\n",
    "    # convert to 8 bit\n",
    "    s_binary = s_binary.astype(np.uint8)\n",
    "\n",
    "    # threshold the lightness channel\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 255\n",
    "    l_binary = l_binary.astype(np.uint8)\n",
    "\n",
    "    # convert to binary image where the lightess AND saturation bits have to be\n",
    "    # both present to contribute, together with the gradient on x axes\n",
    "    binary = np.zeros_like(sxbinary)\n",
    "    binary[((l_binary == 255) & (s_binary == 255) | (sxbinary == 255))] = 255\n",
    "    binary = np.dstack((binary, binary, binary))\n",
    "\n",
    "    # return the images\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def change_perspective(corners):\n",
    "    \"\"\"Change perspective on the input image, that has to be \n",
    "    undistorted. The corners are sent in the following order:\n",
    "    bottom left, top left, top right, bottom right\"\"\"\n",
    "\n",
    "    # create the source region\n",
    "    src = np.float32(corners)\n",
    "\n",
    "    # unpack the corners\n",
    "    bl, tl, tr, br = corners\n",
    "\n",
    "    # adjust top left and top right corner to\n",
    "    # form a rectangle, to be used as destination\n",
    "    tl = (bl[0], 0)\n",
    "    tr = (br[0], 0)\n",
    "\n",
    "    # create the destination rectangle\n",
    "    dst = np.float32([bl, tl, tr, br])\n",
    "\n",
    "    # calculate the matrix to transform from src to dst\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # and from dst to src\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    return M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slide_window(image, startx, nonzerox=None, nonzeroy=None, nwindows=9):\n",
    "    \"\"\"It slide a window from the bottom, with startx x coordinate.\n",
    "    It returns the indices of the points belonging to the line\"\"\"\n",
    "\n",
    "    if nonzerox is None:\n",
    "        # x, y of all nonzero pixels in the image\n",
    "        nonzero = image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # calculate the height of the windows\n",
    "    window_height = np.int(image.shape[0] / nwindows)\n",
    "\n",
    "    # current positions to be updated for each window\n",
    "    currentx = startx\n",
    "\n",
    "    # set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "\n",
    "    # set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # create empty lists to receive left and right lane pixel indices\n",
    "    lane_inds = []\n",
    "\n",
    "    # step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "\n",
    "        # calculate window boundaries in x and y (and right and left)\n",
    "        win_y_low = image.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = image.shape[0] - window * window_height\n",
    "        win_x_low = currentx - margin\n",
    "        win_x_high = currentx + margin\n",
    "\n",
    "        # identify the nonzero pixels in x and y within the window\n",
    "        good_inds = ((nonzeroy >= win_y_low) &\n",
    "                     (nonzeroy < win_y_high) &\n",
    "                     (nonzerox >= win_x_low) &\n",
    "                     (nonzerox < win_x_high)).nonzero()[0]\n",
    "\n",
    "        # append these indices to the lists\n",
    "        lane_inds.append(good_inds)\n",
    "\n",
    "        # if you found > minpix pixels, re-center next window\n",
    "        # on their mean position\n",
    "        if len(good_inds) > minpix:\n",
    "            currentx = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "    # concatenate the arrays of indices\n",
    "    lane_inds = np.concatenate(lane_inds)\n",
    "\n",
    "    return lane_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_curvature_radius(leftx, lefty, rightx, righty):\n",
    "    \"\"\"Calculate the curvature radius, but in the world coordinate\"\"\"\n",
    "\n",
    "    ym_per_pix = 30 / 720    # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700   # meters per pixel in x dimension\n",
    "    y_eval = 720 * ym_per_pix    # eval radius at the bottom of the image\n",
    "\n",
    "    # fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "    # calculate the new radii of curvature\n",
    "    left_curve_radius = ((1 + (2*left_fit_cr[0]*y_eval + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curve_radius = ((1 + (2*right_fit_cr[0]*y_eval + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    # calculate offset, difference between center of the car and center of\n",
    "    # the road\n",
    "\n",
    "    # left and right lane x (in meter) calculated at the bottom of the image\n",
    "    left_x = left_fit_cr[0] * y_eval ** 2 + left_fit_cr[1] * y_eval + left_fit_cr[2]\n",
    "    right_x = right_fit_cr[0] * y_eval ** 2 + right_fit_cr[1] * y_eval + right_fit_cr[2]\n",
    "\n",
    "    # the width of the lane, the center of the car, you can calculate the\n",
    "    # offset too\n",
    "    width = right_x - left_x\n",
    "    car_center = 640 * xm_per_pix\n",
    "    offset = car_center - (width / 2 + left_x)\n",
    "\n",
    "    return left_curve_radius, right_curve_radius, offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_lines(image, p_left_fit=None, p_right_fit=None):\n",
    "    \"\"\"Returns the lane lines as function fit, given a binary image. It uses\n",
    "    the previous fit to speed up the calculations\"\"\"\n",
    "\n",
    "    # if it a 3 channel binary image, make it one channel\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # x, y of all nonzero pixels in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    if p_left_fit is None:\n",
    "        # no previous frame where to start, let's use the sliding\n",
    "        # window method\n",
    "\n",
    "        # take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(image[int(image.shape[0] / 2):, :], axis=0)\n",
    "\n",
    "        # find the peak of the left and right halves of the histogram\n",
    "        # these will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0] / 2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        left_lane_inds = slide_window(image, leftx_base, nonzerox, nonzeroy)\n",
    "        right_lane_inds = slide_window(image, rightx_base, nonzerox, nonzeroy)\n",
    "\n",
    "    else:\n",
    "        # we have a fit from the previous frame, so we use it to calculate\n",
    "        # the points in the +/- margin neighborhood\n",
    "        margin = 100\n",
    "\n",
    "        left_lane_inds = ((nonzerox > (p_left_fit[0] * (nonzeroy ** 2) + p_left_fit[1] * nonzeroy + p_left_fit[2] - margin))\n",
    "                          & (nonzerox < (p_left_fit[0] * (nonzeroy ** 2) + p_left_fit[1] * nonzeroy + p_left_fit[2] + margin)))\n",
    "\n",
    "        right_lane_inds = ((nonzerox > (p_right_fit[0] * (nonzeroy ** 2) + p_right_fit[1] * nonzeroy + p_right_fit[2] - margin)) &\n",
    "                           (nonzerox < (p_right_fit[0] * (nonzeroy ** 2) + p_right_fit[1] * nonzeroy + p_right_fit[2] + margin)))\n",
    "\n",
    "    # extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # calculate the curvature of the lanes\n",
    "    lc, rc, offset = calculate_curvature_radius(leftx, lefty, rightx, righty)\n",
    "\n",
    "    # fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    return left_fit, right_fit, lc, rc, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def static_vars(**kwargs):\n",
    "    def decorate(func):\n",
    "        for k in kwargs:\n",
    "            setattr(func, k, kwargs[k])\n",
    "        return func\n",
    "    return decorate\n",
    "\n",
    "@static_vars(left_fit=None, right_fit=None)\n",
    "def _pipeline(img, cmx, dist):\n",
    "\n",
    "    # un-distort the frame using camera matrix and distortion coeffs\n",
    "    undistort_img = cv2.undistort(img, cmx, dist, None, cmx)\n",
    "\n",
    "    # get the binary image\n",
    "    bin_img = binary(undistort_img)\n",
    "\n",
    "    # define the trapezoid which encloses the road ahead\n",
    "    corners = [(277, 670), (585, 457), (702, 457), (1028, 670)]\n",
    "\n",
    "    # get the matrix to change perspective and the one to reverse\n",
    "    M, Minv = change_perspective(corners)\n",
    "\n",
    "    # image shape needed\n",
    "    img_shape = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # warp the frame\n",
    "    binary_warped = cv2.warpPerspective(bin_img, M, img_shape, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # search for the lines in the frame\n",
    "    _pipeline.left_fit, _pipeline.right_fit, lc, rc, offset = \\\n",
    "        find_lines(binary_warped,\n",
    "                   _pipeline.left_fit,\n",
    "                   _pipeline.right_fit)\n",
    "\n",
    "    # output image\n",
    "    layer = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "\n",
    "    # generate x and y values for plotting\n",
    "    ploty = np.linspace(binary_warped.shape[0] - 1, 0, 30)\n",
    "    left_fitx = _pipeline.left_fit[0] * ploty ** 2 + _pipeline.left_fit[1] * ploty + _pipeline.left_fit[2]\n",
    "    right_fitx = _pipeline.right_fit[0] * ploty ** 2 + _pipeline.right_fit[1] * ploty + _pipeline.right_fit[2]\n",
    "\n",
    "    # zip x and y's to generate array of points\n",
    "    left_pts = np.dstack((left_fitx, ploty))\n",
    "    right_pts = np.flip(np.dstack((right_fitx, ploty)), axis=1)\n",
    "\n",
    "    # create the polygon.\n",
    "    polygon = np.array(np.concatenate((left_pts, right_pts), axis=1), dtype=np.int32)\n",
    "\n",
    "    # draw the polygon in the warped space\n",
    "    cv2.fillPoly(layer, polygon, (0, 255, 0))\n",
    "\n",
    "    # unwarp and add to the original image\n",
    "    layer_unwarp = cv2.warpPerspective(layer, Minv, img_shape, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # write curvature and offset\n",
    "    cv2.putText(img, \"left radius: {0:9.2f} m\".format(lc),\n",
    "                (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(img,\n",
    "                \"right radius:{0:9.2f} m\".format(rc),\n",
    "                (100, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(img,\n",
    "                \"offset:      {0:9.2f} m\".format(offset),\n",
    "                (100, 160), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "\n",
    "    return cv2.addWeighted(img, 1, layer_unwarp, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video.out.mp4\n",
      "[MoviePy] Writing video project_video.out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [02:52<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video.out.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load camera matrix\n",
    "with open(r\"cmx.p\", \"rb\") as cmx_file:\n",
    "    cmx = pickle.load(cmx_file)\n",
    "\n",
    "# load distortion coeffs\n",
    "with open(r\"dist.p\", \"rb\") as dist_file:\n",
    "    dist = pickle.load(dist_file)\n",
    "\n",
    "# partial application on _pipeline function, so I can\n",
    "# send in the camera matrix and distortion coeffs without\n",
    "# relying on globals.\n",
    "pipeline = partial(_pipeline, cmx=cmx, dist=dist)\n",
    "\n",
    "# open the clip\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "\n",
    "# process the clip\n",
    "processed_clip = clip.fl_image(pipeline)\n",
    "\n",
    "# finally save the clip\n",
    "processed_clip.write_videofile(\"project_video.out.mp4\", audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video.out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_video.out.mp4'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
